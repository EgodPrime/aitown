```markdown
# aitown - Technical Specification

**Author:** Egod
**Date:** 2025-10-09
**Project Level:** 2
**Project Type:** Game (多人观察型沙盘)

---

## Implementation Stack

- Backend: Python 3.11+ with FastAPI
- ASGI Server: uvicorn
- Database: SQLite (MVP), JSON fields stored as TEXT
- Testing: pytest
- LLM Adapter: pluggable implementation supporting mock and OpenAI-compatible providers

## Technical Approach

1. Keep the backend simple and modular: separate modules for adapters, simulation engine, repos, services, and routes.
2. Use an Event Bus pattern (in-process queue for MVP) to ensure ordered processing and replayability.
3. LLM calls isolated behind `LLM Adapter` to make switching providers simple via env/config.

## Source Tree (suggested)

- src/
  - app.py
  - adapters/ (llm_adapter, mockllm)
  - services/ (npc_service, simulation_service)
  - repos/ (sqlite_repo)
  - routes/ (player, npc, place, event)

## Development Setup

1. Python 3.11 virtualenv
2. Install dependencies from `pyproject.toml`
3. Run migrations or initialize SQLite schema from provided DDL
4. Start server: `uvicorn src.app:app --reload`

## Testing Approach

- Unit tests with pytest covering services and adapters
- Integration tests for HTTP routes and WebSocket event stream
- Smoke test to spin up server and simulate small number of NPCs

## Deployment Strategy

MVP: single process uvicorn instance serving FastAPI with local SQLite; later migrate to PostgreSQL and multi-process deployment when scaling is required.

---

_This tech spec is intentionally high-level for Level 2 projects. Detailed per-epic tech-specs should be generated by the solutioning workflow._

```